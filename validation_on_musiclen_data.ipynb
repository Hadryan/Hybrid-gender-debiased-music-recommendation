{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Katrin-Leberfinger/Hybrid-gender-debiased-music-recommendation/blob/main/validation_on_musiclen_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkBFbi9YA_ys"
      },
      "source": [
        "# Model validations\n",
        "\n",
        "Code Source:\n",
        "https://gist.github.com/shubhamagarwal92/37ccb747f7130a35a8e76aa66d60e014\n",
        "\n",
        "Interesting articles\n",
        "https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#31-running-bert-on-our-text\n",
        "https://www.kaggle.com/hassanamin/bert-pytorch-cola-classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWHMmzSHaV4j",
        "outputId": "88efba35-ef7f-44c0-e040-dca3f1797e5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L9D-5zOmltBw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from transformers import BertConfig, BertPreTrainedModel, BertModel, BertForSequenceClassification\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertModel, AdamW\n",
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "from sklearn.metrics import f1_score\n",
        "import ast\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXEH2KDKXjCM"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lh1zKzGuXlXM"
      },
      "outputs": [],
      "source": [
        "# data: track_artist -\ttrack_name -\ttrack_tag - track_id\n",
        "\n",
        "def read_items_data(data, id_col, text_col):\n",
        "  items = dict()\n",
        "  item2pos = dict()\n",
        "  pos2item = dict()\n",
        "  token2id = dict()\n",
        "  num_items = 1\n",
        "  num_tokens = 1\n",
        "  max_item_len = 0\n",
        "\n",
        "  for index, row in data.iterrows():\n",
        "    # for each item:\n",
        "    item_id = row[id_col]\n",
        "    item_words = []\n",
        "    item2pos[item_id] = num_items\n",
        "    pos2item[num_items] = item_id\n",
        "    \n",
        "    for word in row[text_col].split(' '): \n",
        "    #  for each word:\n",
        "      try:\n",
        "        token2id[word]\n",
        "      except:\n",
        "        token2id[word] = num_tokens\n",
        "        num_tokens = num_tokens + 1\n",
        "    \n",
        "\n",
        "      item_words.append(token2id[word])\n",
        "\n",
        "    if len(item_words) > max_item_len:\n",
        "        max_item_len = len(item_words)\n",
        "\n",
        "    items[item_id] = item_words\n",
        "    num_items = num_items + 1\n",
        "\n",
        "  return items, item2pos, pos2item, token2id, max_item_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4wBsH6CFBrhZ"
      },
      "outputs": [],
      "source": [
        "# data: track_artist -\ttrack_name -\ttrack_tag - track_id\n",
        "# NEW VERSION USING BERT\n",
        "\n",
        "def read_items_data_bert(data, id_col, text_col, max_length=512):\n",
        "  tokenizer = BertTokenizer.from_pretrained('prajjwal1/bert-tiny') \n",
        "  items = torch.Tensor([])\n",
        "  attentions = torch.Tensor([])\n",
        "  item2pos = dict()\n",
        "  pos2item = dict()\n",
        "  token2id = dict()\n",
        "  num_items = 0\n",
        "  num_tokens = 0\n",
        "  max_item_len = 0\n",
        "\n",
        "  for index, row in data.iterrows():\n",
        "    # for each item:\n",
        "    item_id = row[id_col]\n",
        "    item_words = []\n",
        "    item2pos[item_id] = num_items\n",
        "    pos2item[num_items] = item_id\n",
        "\n",
        "\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        row[text_col], \n",
        "        None,\n",
        "        add_special_tokens=True,\n",
        "        max_length = max_length,\n",
        "        pad_to_max_length=True\n",
        "        \n",
        "    )\n",
        "\n",
        "    tokens = inputs[\"input_ids\"]\n",
        "    attention = inputs['attention_mask']\n",
        "    tokens=torch.tensor(tokens, dtype=torch.long).unsqueeze(0)\n",
        "    attention=torch.tensor(attention, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "    items = torch.concat((items, tokens))\n",
        "    attentions = torch.concat((attentions, attention))\n",
        "    num_items = num_items + 1\n",
        "\n",
        "  return items, attentions, item2pos, pos2item, token2id, max_item_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MXu90sp8XmdZ"
      },
      "outputs": [],
      "source": [
        "# data: user_id - item_id - rating\n",
        "# playcount: normalize/ binary (>1:1 or <=1:0)\n",
        "\n",
        "def read_ratings_data(data, item2pos, id_col, rating_col, user_col):\n",
        "    ratings = torch.Tensor(len(data), 3)\n",
        "    user2id = dict()\n",
        "    id2user = dict()\n",
        "    num_users = 0\n",
        "    i = 0\n",
        "    for _, row in data.iterrows():\n",
        "        raw_user = row[user_col] \n",
        "\n",
        "        try:\n",
        "          user2id[raw_user]\n",
        "        except:\n",
        "          user2id[raw_user] = num_users\n",
        "          id2user[num_users] = raw_user\n",
        "          num_users = num_users + 1\n",
        "\n",
        "        user = user2id[raw_user]\n",
        "        item = int(item2pos[row[id_col]]) #track_id\n",
        "        rating = int(row[rating_col]) # count\n",
        "\n",
        "        ratings[i][0] = user\n",
        "        ratings[i][1] = item\n",
        "        ratings[i][2] = rating / data[rating_col].max()\n",
        "        i = i+1\n",
        "\n",
        "\n",
        "    return ratings, user2id, id2user\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hONctxsSSuKI"
      },
      "outputs": [],
      "source": [
        "def pad_items_data(items, item2pos, max_item_len):\n",
        "    data = torch.zeros(len(items), max_item_len)\n",
        "\n",
        "    for item_id, tokens in enumerate(items):\n",
        "      token = items[tokens]\n",
        "      for i, t in enumerate(token):\n",
        "        data[item_id,i] = t\n",
        "\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzTFm7XWXmXv",
        "outputId": "0e896c27-db30-452f-ef8a-cff8b9c43c45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWWKtwJxXmQC",
        "outputId": "51b0d777-2331-4318-cda9-c73d43668b55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Master Thesis/data\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Master\\ Thesis/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFx4YTh70Zik"
      },
      "source": [
        "## Read Data: MovieLen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G6cBGKTw0gaR"
      },
      "outputs": [],
      "source": [
        "data_movies = pd.read_csv(\"movies/movies_abstracts.csv\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "data_interaction = pd.read_csv(\"movies/ratings.csv\").drop(['timestamp'],axis=1)\n",
        "\n",
        "data_movies = pd.merge(data_movies, data_interaction[['movieId']], 'inner').drop_duplicates()\n",
        "data_interaction = pd.merge(data_interaction, data_movies[['movieId']], 'inner')\n",
        "\n",
        "rating_col = 'rating'\n",
        "item_col = 'movieId'\n",
        "user_col = 'userId'\n",
        "text_col = 'abstract'\n",
        "data_items_eval = data_movies\n",
        "\n",
        "data_interaction.loc[data_interaction.rating<4., 'rating'] = 0.\n",
        "data_interaction.loc[data_interaction.rating>=4., 'rating'] = 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf103qDF0cNv"
      },
      "source": [
        "## Read Data: Lyrics "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lTSGXhgqhfXI"
      },
      "outputs": [],
      "source": [
        "# data_tracks_lyrics = pd.read_csv(\"music/data_tracks_lyrics.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "# data_tracks_tags_lyrics = pd.read_csv(\"music/data_tracks_tags_lyrics.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "# #data_tracks_tags_lyrics=data_tracks_tags_lyrics.iloc[:-1,:]\n",
        "# data_interaction = pd.read_csv(\"music/data_user_track_interaction.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)\n",
        "# data_user = pd.read_csv(\"music/data_user.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)\n",
        "\n",
        "# data_interaction.loc[data_interaction['count']<2., 'count'] = 0.\n",
        "# data_interaction.loc[data_interaction['count']>=2., 'count'] = 1.\n",
        "\n",
        "# rating_col = 'count'\n",
        "# item_col = 'track_id'\n",
        "# user_col = 'user_id'\n",
        "# text_col = 'tags'\n",
        "# data_items_eval = data_tracks_tags_lyrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "# selected_user = random.sample(list(data_interaction.user_id.unique()), 1000)\n",
        "# data_interaction = data_interaction.loc[data_interaction.user_id.isin(selected_user)]"
      ],
      "metadata": {
        "id": "g7trIWVG6xUY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = 0\n",
        "i = 0\n",
        "for d in data_items_eval[text_col]:\n",
        "  l = l+ len(d.split())\n",
        "  i = i+1\n",
        "l/i"
      ],
      "metadata": {
        "id": "lugVF1PfY4Gt",
        "outputId": "2a344e9c-6856-4885-8469-96748776735f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115.02414486921529"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CV and balance data set"
      ],
      "metadata": {
        "id": "ylBY96MuqFyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_interaction['fold'] = np.random.randint(1, 6, data_interaction.shape[0])\n",
        "\n",
        "import random\n",
        "random.seed(123)\n",
        "idx = []\n",
        "for _,df in data_interaction.groupby('fold'):\n",
        "  len_pos = len(df[df[rating_col]==1])\n",
        "  len_neg = len(df[df[rating_col]==0])\n",
        "  if len_pos < len_neg:\n",
        "    df = df[df[rating_col]==0].sample(len_pos).append(df[df[rating_col]==1])\n",
        "  elif len_pos > len_neg:\n",
        "    df = df[df[rating_col]==1].sample(len_pos).append(df[df[rating_col]==0])\n",
        "  idx.extend(df.index.values.tolist())\n",
        "\n",
        "test_fold = 1\n",
        "\n",
        "data_interaction_train = data_interaction.loc[data_interaction.fold != test_fold, [user_col, item_col, rating_col]]\n",
        "data_interaction_test = data_interaction.loc[data_interaction.fold == test_fold, [user_col, item_col, rating_col]]"
      ],
      "metadata": {
        "id": "MR65uPJ6qE9R"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_interaction_train"
      ],
      "metadata": {
        "id": "vpNYcmGWrUAm",
        "outputId": "41699e18-f947-4931-c7bb-7a6fb539aeff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       userId  movieId  rating\n",
              "0           1        1     1.0\n",
              "2           7        1     1.0\n",
              "3          15        1     0.0\n",
              "5          18        1     0.0\n",
              "6          19        1     1.0\n",
              "...       ...      ...     ...\n",
              "70190     610   160341     0.0\n",
              "70191     610   160527     1.0\n",
              "70192     610   160836     0.0\n",
              "70193     610   163937     0.0\n",
              "70194     610   163981     0.0\n",
              "\n",
              "[56149 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63105101-6574-4359-ae6b-ab7eb4cd90c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70190</th>\n",
              "      <td>610</td>\n",
              "      <td>160341</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70191</th>\n",
              "      <td>610</td>\n",
              "      <td>160527</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70192</th>\n",
              "      <td>610</td>\n",
              "      <td>160836</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70193</th>\n",
              "      <td>610</td>\n",
              "      <td>163937</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70194</th>\n",
              "      <td>610</td>\n",
              "      <td>163981</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>56149 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63105101-6574-4359-ae6b-ab7eb4cd90c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63105101-6574-4359-ae6b-ab7eb4cd90c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63105101-6574-4359-ae6b-ab7eb4cd90c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_interaction_test = data_interaction_test[data_interaction_test.userId.isin([7, 15, 17])]"
      ],
      "metadata": {
        "id": "X41t20UIrVN0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1VnHcVWBFIP"
      },
      "source": [
        "# Ask Me Anything Rating\n",
        "\n",
        "Code source: https://github.com/nlp-deepcbrs/amar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbf_Xg4sE_gu"
      },
      "source": [
        "## **BERT Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrDzG95DcA_8",
        "outputId": "59a147e0-00b0-4ac6-99cd-8c7d408771cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "items, attentions, item2pos, pos2item, token2id, max_item_len = read_items_data_bert(data_items_eval, item_col, text_col, 128)\n",
        "ratings_train, user2id_train, id2user_train = read_ratings_data(data_interaction_train, item2pos,  item_col, rating_col, user_col)\n",
        "\n",
        "ratings_test, user2id_test, id2user_test = read_ratings_data(data_interaction_test, item2pos,  item_col, rating_col, user_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GHWjCxuHb6cX"
      },
      "outputs": [],
      "source": [
        "class AMARBert(nn.Module):\n",
        "    def __init__(self, hidden_dense_layer_size, item_embeddings_size, num_users):\n",
        "        super(AMARBert, self).__init__()\n",
        "        #self.model1_layer2 = BertModel.from_pretrained('prajjwal1/bert-tiny')#('bert-base-uncased')\n",
        "        self.model1_layer2 = BertModel.from_pretrained('prajjwal1/bert-tiny')\n",
        "        self.model1_layer3 = nn.Dropout(p=0.2)\n",
        "\n",
        "        self.model2_layer1 = nn.Embedding(num_users, user_embeddings_size)\n",
        "        \n",
        "        self.linear = nn.Linear(hidden_dense_layer_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #_, y1 = self.model1_layer2(x[0], attention_mask = x[2],  return_dict=False)\n",
        "        output, y1 = self.model1_layer2(x[0],  return_dict=False)\n",
        "        #y1 = output[:, 0, :]\n",
        "        # pooled_output (=y1) is the output of the CLS token\n",
        "        # \"Since BERT is transformer based contextual model, the idea is [CLS] token would have captured the entire context and would be sufficient for simple downstream tasks such as classification.\"\n",
        "        # https://stackoverflow.com/questions/63673511/how-to-use-the-outputs-of-bert-model?rq=1\n",
        "        # https://towardsdatascience.com/bert-to-the-rescue-17671379687f\n",
        "        #y1 = self.model1_layer3(y1)\n",
        "        \n",
        "        y2 = self.model2_layer1(x[1])\n",
        "\n",
        "        y = torch.cat([y1, y2], 1)\n",
        "        y = self.linear(y)\n",
        "        return self.sigmoid(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJdsCzCuqzHQ",
        "outputId": "f20ce266-34db-4a53-b34b-6c9ea6c4e23c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Params: items_data, ratings_data, genres_data\n",
        "device = 'cuda'\n",
        "\n",
        "import numpy as np\n",
        "num_examples=ratings_train.size(0)\n",
        "item_embeddings_size = 128\n",
        "user_embeddings_size = 100\n",
        "genre_embeddings_size = 128\n",
        "hidden_dense_layer_size = item_embeddings_size + user_embeddings_size\n",
        "num_tokens = 128\n",
        "num_users = len(data_interaction[user_col].drop_duplicates())\n",
        "\n",
        "model = AMARBert(hidden_dense_layer_size, user_embeddings_size, num_users)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Vnqy-3XBqQ6p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "4088e4aa-2477-4a0a-bf4d-2d2e2e0a2356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average cost per epoch:  tensor(0.6948, grad_fn=<DivBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-acec153474a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# backward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-3430aeeb3984>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#_, y1 = self.model1_layer2(x[0], attention_mask = x[2],  return_dict=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel1_layer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m#y1 = output[:, 0, :]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# pooled_output (=y1) is the output of the CLS token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1008\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m                 )\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         )\n\u001b[1;32m    479\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key_query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "criterion = nn.BCEWithLogitsLoss() \n",
        "# # https://huggingface.co/transformers/v1.0.0/migration.html\n",
        "lr = 1e-3\n",
        "num_total_steps = 1000\n",
        "num_warmup_steps = 100\n",
        "warmup_proportion = float(num_warmup_steps) / float(num_total_steps)  \n",
        "optimizer = AdamW(model.parameters(), lr=lr, correct_bias=False)  \n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "   optimizer,\n",
        "   num_warmup_steps=num_warmup_steps,\n",
        "   num_training_steps=num_total_steps\n",
        ")\n",
        "\n",
        "\n",
        "num_epochs=5\n",
        "batch_size=256 \n",
        "#batch_size=32\n",
        "num_examples=ratings_train.shape[0]\n",
        "\n",
        "cost_per_epoch = []\n",
        "\n",
        "for e in range(num_epochs):\n",
        "    # shuffle and split training examples in batches\n",
        "    indices = torch.randperm(num_examples).split(batch_size)\n",
        "\n",
        "    #remove last element so that all the batches have equal size\n",
        "    indices = indices[:len(indices)-1] \n",
        "\n",
        "    average_cost = 0\n",
        "\n",
        "    for t, v in enumerate(indices):\n",
        "        #items positions\n",
        "        curr_items_ids_batch = ratings_train[v, 1]\n",
        "\n",
        "        # items descriptions\n",
        "        curr_items_batch = items[curr_items_ids_batch.numpy(),:].to(device)\n",
        "        curr_attentions_batch = attentions[curr_items_ids_batch.numpy(),:].to(device)\n",
        "        \n",
        "        # users ids\n",
        "        curr_users_batch = ratings_train[v, 0].to(device)\n",
        "\n",
        "        # model inputs\n",
        "        inputs = [ curr_items_batch.type(torch.LongTensor), curr_users_batch.type(torch.LongTensor), curr_attentions_batch.type(torch.LongTensor)]\n",
        "\n",
        "        # model targets\n",
        "        targets = ratings_train[v, 2]\n",
        "\n",
        "        # callback that does a single batch optimization step\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # backward propagation\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "      \n",
        "        outputs = outputs.reshape(-1,)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        # evaluate current loss function value\n",
        "        average_cost = average_cost + loss\n",
        "        \n",
        "\n",
        "    # evaluate average cost per epoch\n",
        "    average_cost = average_cost / len(indices)\n",
        "    cost_per_epoch.append(average_cost)\n",
        "    print(\"Average cost per epoch: \", average_cost)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.max()"
      ],
      "metadata": {
        "id": "oJahCS4st51Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH1Njid6OwL8"
      },
      "source": [
        "## **BERT**: Get predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXOMsdEcOvQ2"
      },
      "outputs": [],
      "source": [
        "indices = torch.arange(0, ratings_test.shape[0]).split(1)\n",
        "predictions = {}\n",
        "feature_vectors = {}\n",
        "weights = {}\n",
        "\n",
        "indices = indices[:len(indices)-1] \n",
        "\n",
        "for t, v in enumerate(indices):\n",
        "\n",
        "  curr_items_ids_batch = ratings_test[v.numpy(), 1]\n",
        "\n",
        "  curr_items_batch = items[curr_items_ids_batch.numpy(),:].to(device)\n",
        "  curr_attentions_batch = attentions[curr_items_ids_batch.numpy(),:].to(device)\n",
        "\n",
        "  curr_users_batch = ratings_test[v.numpy(), 0].to(device)\n",
        "\n",
        "  inputs = [ curr_items_batch.type(torch.LongTensor), curr_users_batch.type(torch.LongTensor), curr_attentions_batch.type(torch.LongTensor)]\n",
        "  \n",
        "\n",
        "  targets = model(inputs)\n",
        "\n",
        "  \n",
        "\n",
        "  # save prediction for each user\n",
        "  real_user_id = id2user_test[curr_users_batch[0].item()]\n",
        "  \n",
        "  try:\n",
        "    predictions[real_user_id] \n",
        "  except:\n",
        "    predictions[real_user_id] = []\n",
        "\n",
        "  predictions[real_user_id].append([pos2item[curr_items_ids_batch.item()], \n",
        "                                    targets[0].item()])\n",
        "  \n",
        "        \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epmQfDr0Vvzc"
      },
      "outputs": [],
      "source": [
        "topn=10\n",
        "results = []\n",
        "results_df = pd.DataFrame(columns = [user_col, item_col, rating_col])\n",
        "\n",
        "for user in predictions:\n",
        "    item_list = []\n",
        "    user_prediction = predictions[user]\n",
        "\n",
        "    user_prediction = sorted(user_prediction,key=lambda x: (x[1]), reverse=True)\n",
        "    n = 1\n",
        "    for item, rating in user_prediction:\n",
        "        if item  not in item_list:\n",
        "          item_list.append(item)\n",
        "          results_df = pd.concat((results_df, pd.DataFrame(data={user_col:[user],item_col:[item],rating_col:[rating]})))\n",
        "          results.append([user, item, rating])\n",
        "          if n >= topn:\n",
        "              break\n",
        "          n = n + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2mh40ShE7vz"
      },
      "source": [
        "## Models from AMAR paper **SeqLSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7mdKz_-bcDqp"
      },
      "outputs": [],
      "source": [
        "items, item2pos, pos2item, token2id, max_item_len = read_items_data(data_items_eval, item_col, text_col)\n",
        "items = pad_items_data(items, item2pos, max_item_len)\n",
        "\n",
        "ratings_train, user2id_train, id2user_train = read_ratings_data(data_interaction_train, item2pos,  item_col, rating_col, user_col)\n",
        "\n",
        "ratings_test, user2id_test, id2user_test = read_ratings_data(data_interaction_test, item2pos, item_col, rating_col, user_col)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "9PctgDxD2CAr"
      },
      "outputs": [],
      "source": [
        "class AMARSeqLSTM(nn.Module):\n",
        "    def __init__(self, hidden_dense_layer_size, num_tokens, item_embeddings_size, num_users):\n",
        "        super(AMARSeqLSTM, self).__init__()\n",
        "        self.model1_layer1 = nn.EmbeddingBag(num_tokens + 1, item_embeddings_size)\n",
        "        self.model1_layer2 = nn.LSTM(input_size=item_embeddings_size, hidden_size= item_embeddings_size,\n",
        "                                num_layers=5, dropout=0.2, batch_first=True)\n",
        "        #self.model1_layer3 = nn.AvgPool1d(2) \n",
        "        self.model1_layer3 = nn.Dropout(0.2) \n",
        "\n",
        "        self.model2_layer1 = nn.Embedding(num_users, user_embeddings_size)\n",
        "        \n",
        "        self.linear = nn.Linear(hidden_dense_layer_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self,x, hidden):\n",
        "        y1 = self.model1_layer1(x[0].type(torch.LongTensor))\n",
        "        y1, hidden  = self.model1_layer2(y1.reshape(y1.shape[0], 1, y1.shape[1]), hidden)\n",
        "        y1 = self.model1_layer3(y1)\n",
        "        y1 = y1.reshape(y1.shape[0], y1.shape[-1])\n",
        "        \n",
        "        y2 = self.model2_layer1(x[1])\n",
        "        y = torch.cat([y1, y2], 1)\n",
        "        y = self.linear(y)\n",
        "        return self.sigmoid(y), hidden\n",
        "\n",
        "    def initialize_hidden_state(self,batch_size):\n",
        "      weight=next(self.parameters()).data\n",
        "      if(torch.cuda.is_available()):\n",
        "       hidden=(weight.new(5,batch_size,item_embeddings_size).zero_().cuda(),weight.new(5,batch_size,item_embeddings_size).zero_().cuda())\n",
        "      else:\n",
        "        hidden=(weight.new(5,batch_size,item_embeddings_size).zero_(),weight.new(5,batch_size,item_embeddings_size).zero_())\n",
        "        \n",
        "      return hidden\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "z_DhmDbMBNuY"
      },
      "outputs": [],
      "source": [
        "# Params: items_data, ratings_data, genres_data, batch_size\n",
        "device = 'cuda'\n",
        "\n",
        "import numpy as np\n",
        "num_examples=ratings_train.size(0)\n",
        "item_embeddings_size = 128\n",
        "user_embeddings_size = 10\n",
        "genre_embeddings_size = 128\n",
        "hidden_dense_layer_size = item_embeddings_size + user_embeddings_size\n",
        "num_tokens = len(token2id)\n",
        "num_users = len(data_interaction[user_col].drop_duplicates())\n",
        "\n",
        "# ADD genre and tags\n",
        "\n",
        "model = AMARSeqLSTM( hidden_dense_layer_size, num_tokens, item_embeddings_size, num_users).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmYv23UnZ0Dz"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De6UsBemBNps"
      },
      "outputs": [],
      "source": [
        "#criterion = nn.BCEWithLogitsLoss() \n",
        "criterion = nn.BCELoss()\n",
        "#criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr= 1e-3, alpha=0.9)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# remove later\n",
        "ratings_train = ratings_train[ratings_train[:,1]<len(items),]\n",
        "ratings_train = ratings_train[ratings_train[:,0]<num_users,]\n",
        "\n",
        "num_epochs=10\n",
        "#batch_size=256 \n",
        "batch_size=32\n",
        "num_examples=ratings_train.shape[0]\n",
        "\n",
        "cost_per_epoch = []\n",
        "\n",
        "for e in range(num_epochs):\n",
        "    hidden_state=model.initialize_hidden_state(batch_size)\n",
        "    # shuffle and split training examples in batches\n",
        "    indices = torch.randperm(num_examples).split(batch_size)\n",
        "\n",
        "    #remove last element so that all the batches have equal size\n",
        "    indices = indices[:len(indices)-1] \n",
        "\n",
        "    average_cost = 0\n",
        "\n",
        "    for t, v in enumerate(indices):\n",
        "        hidden_state=tuple([element.data for element in hidden_state])\n",
        "        #items positions\n",
        "        curr_items_ids_batch = ratings_train[v, 1]\n",
        "\n",
        "        # items descriptions\n",
        "        curr_items_batch = items[curr_items_ids_batch.numpy(),:].to(device)\n",
        "        \n",
        "        # users ids\n",
        "        curr_users_batch = ratings_train[v, 0].to(device)\n",
        "\n",
        "        # model inputs\n",
        "        inputs = [ curr_items_batch.type(torch.LongTensor), curr_users_batch.type(torch.LongTensor)]\n",
        "\n",
        "        # model targets\n",
        "        targets = ratings_train[v, 2]\n",
        "\n",
        "        # callback that does a single batch optimization step\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # backward propagation\n",
        "        outputs,hidden_state=model(inputs,hidden_state)\n",
        "        outputs = outputs.reshape(-1,)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # evaluate current loss function value\n",
        "        average_cost = average_cost + loss\n",
        "        \n",
        "\n",
        "    # evaluate average cost per epoch\n",
        "    average_cost = average_cost / len(indices)\n",
        "    cost_per_epoch.append(average_cost)\n",
        "    print(\"Average cost per epoch: \", average_cost)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "metadata": {
        "id": "1a78vQ2p5ear"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anLiyjhSZ2Jg"
      },
      "source": [
        "## **SeqLSTM**: Get predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37UaYOzc_lsn"
      },
      "outputs": [],
      "source": [
        "# # Version from github\n",
        "\n",
        "# # remove later\n",
        "# #ratings_test = ratings_test[ratings_test[:,1]<len(items),]\n",
        "# #ratings_test = ratings_test[ratings_test[:,0]<num_users,]\n",
        "# topn = 10\n",
        "\n",
        "# indices = torch.arange(0, ratings_test.shape[0]).split(batch_size)\n",
        "# predictions = {}\n",
        "\n",
        "# indices = indices[:len(indices)-1] \n",
        "\n",
        "# for t, v in enumerate(indices):\n",
        "\n",
        "#   curr_items_ids_batch = ratings_test[v.numpy(), 1]\n",
        "\n",
        "#   curr_items_batch = items[curr_items_ids_batch.numpy(),:].to(device)\n",
        "\n",
        "#   curr_users_batch = ratings_test[v.numpy(), 0].to(device)\n",
        "\n",
        "#   inputs = [ curr_items_batch.type(torch.LongTensor), curr_users_batch.type(torch.LongTensor)]\n",
        "  \n",
        "#   #if t == len(indices):\n",
        "#   #  last_batch_size = v.shape[0]\n",
        "#   #  curr_users_batch = torch.cat(curr_users_batch, torch.zeros(batch_size-v.shape[0], 0).to(device), 0)\n",
        "#   #  curr_items_batch = torch.cat(curr_items_batch, torch.zeros(batch_size-v.shape[0], max_item_len).to(device), 0)\n",
        "\n",
        "\n",
        "#   targets = model(inputs)\n",
        "\n",
        "#   # save prediction for each user\n",
        "\n",
        "#   for index in range(targets.shape[0]):\n",
        "#       real_user_id = id2user_test[curr_users_batch[index].item()]\n",
        "#       try:\n",
        "#          predictions[real_user_id] \n",
        "#       except:\n",
        "#         predictions[real_user_id] = []\n",
        "#       predictions[real_user_id].append([pos2item[curr_items_ids_batch[index].item()], \n",
        "#                                        targets[index].item()])\n",
        "      \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New version\n",
        "\n",
        "indices = ratings_test[:,0].unique()\n",
        "predictions = {}\n",
        "hidden_state=model.initialize_hidden_state(1)\n",
        "for curr_users_batch in indices:\n",
        "  \n",
        "\n",
        "  curr_users_batch = curr_users_batch.to(device).reshape(1,)\n",
        " # indices_items = ratings_test[ratings_test[:,0] == curr_users_batch.item()][:,1].unique()\n",
        "  indices_items = ratings_train[:,1].unique()[:2500]\n",
        "  for curr_items_ids_batch in indices_items:\n",
        "    \n",
        "    curr_items_ids_batch = int(curr_items_ids_batch.item())\n",
        "\n",
        "    curr_items_batch = items[curr_items_ids_batch,:].to(device).reshape(1,-1)\n",
        "\n",
        "    \n",
        "    inputs = [ curr_items_batch.type(torch.LongTensor), curr_users_batch.type(torch.LongTensor)]\n",
        "    \n",
        "    outputs, hidden_state = model(inputs, hidden_state)\n",
        "    outputs = outputs.reshape(-1,)\n",
        "    item_list = []\n",
        "\n",
        "    real_user_id = id2user_test[curr_users_batch[0].item()]\n",
        "    \n",
        "    try:\n",
        "      predictions[real_user_id] \n",
        "    except:\n",
        "      predictions[real_user_id] = []\n",
        "\n",
        "    predictions[real_user_id].append([pos2item[curr_items_ids_batch], \n",
        "                                      outputs[0].item()])\n",
        "        \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LAkiUftJ8W7T"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Mxjg0mbcVse0"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "results_df = pd.DataFrame(columns = [user_col, item_col, rating_col])\n",
        "\n",
        "for user in predictions:\n",
        "    user_prediction = predictions[user]\n",
        "\n",
        "    user_prediction = sorted(user_prediction,key=lambda x: (x[1]), reverse=True)\n",
        "    n = 1\n",
        "    for item, rating in user_prediction:\n",
        "        results_df = pd.concat((results_df, pd.DataFrame(data={user_col:[user],item_col:[item],rating_col:[rating]})))\n",
        "        results.append([user, item, rating])\n",
        "     #   if n >= topn:\n",
        "     #       break\n",
        "        n = n + 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df[results_df.userId == 7].head(10)"
      ],
      "metadata": {
        "id": "YNZEchw43t8N",
        "outputId": "36b4bffa-1961-41aa-abeb-31be98d30bc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId movieId    rating\n",
              "0     7.0    1203  0.829153\n",
              "0     7.0     924  0.811689\n",
              "0     7.0    2066  0.788920\n",
              "0     7.0    1208  0.785936\n",
              "0     7.0    1204  0.782513\n",
              "0     7.0     926  0.782363\n",
              "0     7.0     588  0.782172\n",
              "0     7.0     356  0.780328\n",
              "0     7.0      16  0.780216\n",
              "0     7.0    1277  0.777891"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2146a54e-f90e-4249-b600-5e8824fe5ae3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1203</td>\n",
              "      <td>0.829153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>924</td>\n",
              "      <td>0.811689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>2066</td>\n",
              "      <td>0.788920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1208</td>\n",
              "      <td>0.785936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1204</td>\n",
              "      <td>0.782513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>926</td>\n",
              "      <td>0.782363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>588</td>\n",
              "      <td>0.782172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>356</td>\n",
              "      <td>0.780328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>16</td>\n",
              "      <td>0.780216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1277</td>\n",
              "      <td>0.777891</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2146a54e-f90e-4249-b600-5e8824fe5ae3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2146a54e-f90e-4249-b600-5e8824fe5ae3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2146a54e-f90e-4249-b600-5e8824fe5ae3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df[results_df.userId == 17].head(10)"
      ],
      "metadata": {
        "id": "xuX9DYKI3pLn",
        "outputId": "0acb283f-9b4e-405c-d9ea-5035ac9402e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId movieId    rating\n",
              "0    17.0    1207  0.933986\n",
              "0    17.0    1227  0.927950\n",
              "0    17.0    1208  0.927367\n",
              "0    17.0    1214  0.925842\n",
              "0    17.0     912  0.920312\n",
              "0    17.0    1213  0.919956\n",
              "0    17.0    1246  0.917216\n",
              "0    17.0     588  0.916404\n",
              "0    17.0    1941  0.914420\n",
              "0    17.0    1023  0.913637"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aacb229f-1a94-42ea-a606-b3c4ed8954eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.0</td>\n",
              "      <td>1207</td>\n",
              "      <td>0.933986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.0</td>\n",
              "      <td>1227</td>\n",
              "      <td>0.927950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.0</td>\n",
              "      <td>1208</td>\n",
              "      <td>0.927367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.0</td>\n",
              "      <td>1214</td>\n",
              "      <td>0.925842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.0</td>\n",
              "      <td>912</td>\n",
              "      <td>0.920312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.0</td>\n",
              "      <td>1213</td>\n",
              "      <td>0.919956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.0</td>\n",
              "      <td>1246</td>\n",
              "      <td>0.917216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.0</td>\n",
              "      <td>588</td>\n",
              "      <td>0.916404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.0</td>\n",
              "      <td>1941</td>\n",
              "      <td>0.914420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.0</td>\n",
              "      <td>1023</td>\n",
              "      <td>0.913637</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aacb229f-1a94-42ea-a606-b3c4ed8954eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aacb229f-1a94-42ea-a606-b3c4ed8954eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aacb229f-1a94-42ea-a606-b3c4ed8954eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df[results_df.userId == 15].head(10)"
      ],
      "metadata": {
        "id": "5xndR6Q1LO3Q",
        "outputId": "a2f1513a-0722-46f0-b8b8-67012423f22a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId movieId    rating\n",
              "0    15.0    1213  0.612235\n",
              "0    15.0    1246  0.584999\n",
              "0    15.0     926  0.570376\n",
              "0    15.0     897  0.565124\n",
              "0    15.0    1227  0.565048\n",
              "0    15.0     924  0.552918\n",
              "0    15.0    1214  0.552261\n",
              "0    15.0    1200  0.550493\n",
              "0    15.0     904  0.550368\n",
              "0    15.0    1228  0.543278"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cafcccf8-8418-4e79-97d9-7429b3f0f19a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1213</td>\n",
              "      <td>0.612235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1246</td>\n",
              "      <td>0.584999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.0</td>\n",
              "      <td>926</td>\n",
              "      <td>0.570376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.0</td>\n",
              "      <td>897</td>\n",
              "      <td>0.565124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1227</td>\n",
              "      <td>0.565048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.0</td>\n",
              "      <td>924</td>\n",
              "      <td>0.552918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1214</td>\n",
              "      <td>0.552261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1200</td>\n",
              "      <td>0.550493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.0</td>\n",
              "      <td>904</td>\n",
              "      <td>0.550368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1228</td>\n",
              "      <td>0.543278</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cafcccf8-8418-4e79-97d9-7429b3f0f19a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cafcccf8-8418-4e79-97d9-7429b3f0f19a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cafcccf8-8418-4e79-97d9-7429b3f0f19a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxT5OGjKMDi7"
      },
      "source": [
        "## **Most Popular**: Get Predictions\n",
        "\n",
        "https://www.kaggle.com/gspmoreira/recommender-systems-in-python-101#Popularity-model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topn = 10\n",
        "\n",
        "item_popularity_df = data_interaction.groupby(item_col)[rating_col].sum().sort_values(ascending=False).reset_index()\n",
        "\n",
        "predictions = {}\n",
        "\n",
        "for real_user_id in data_interaction_test.userId:\n",
        "    predictions[real_user_id] = []\n",
        "    items_to_ignore = data_interaction_train[data_interaction_train[user_col] == real_user_id]['movieId'].values\n",
        "    item_popularity_df_user = item_popularity_df[~item_popularity_df[item_col].isin(items_to_ignore)]\n",
        "    predictions[real_user_id].append(item_popularity_df_user.head(topn)[item_col].values.tolist())\n",
        "      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6385-rmtpov",
        "outputId": "dde0ab8b-dd3d-4705-9f5f-8da7a6ecb773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-251-6d651b8a619b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreal_user_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mitems_to_ignore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_interaction_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_interaction_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mreal_user_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movieId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mitem_popularity_df_user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_popularity_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mitem_popularity_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems_to_ignore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreal_user_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_popularity_df_user\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__invert__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1526\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1527\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__invert__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgbk0OCAVDS8"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "results_df = pd.DataFrame(columns = [user_col, item_col, rating_col])\n",
        "\n",
        "for user in predictions:\n",
        "    user_prediction = predictions[user][0]\n",
        "    for item in user_prediction:\n",
        "        rating = 1.\n",
        "        results_df = pd.concat((results_df, pd.DataFrame(data={user_col:[user],item_col:[item],rating_col:[rating]})))\n",
        "        results.append([user, item, rating])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxzLZWaLAhUZ"
      },
      "source": [
        "# Evaluate predictions (for all methods) \n",
        "\n",
        "Scores: F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DTstEsi72xS",
        "outputId": "2ca045de-5928-40a0-8b76-ecb93e6ea3fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score:  0.6116116466860201\n"
          ]
        }
      ],
      "source": [
        "scores = []\n",
        "for user, df in results_df.groupby(user_col):\n",
        "  df = df.drop_duplicates(subset=item_col)\n",
        "  y_true_sorted = data_interaction_test.loc[data_interaction_test[user_col] == user].sort_values(rating_col, ascending=False)\n",
        "  y_true_df = pd.merge(data_items_eval[[item_col]], y_true_sorted[[item_col, rating_col]], 'left').fillna(0)\n",
        "  y_true_ndcg = y_true_df[rating_col].values\n",
        "  y_true_df.loc[y_true_df[rating_col] > 0, rating_col] = 1\n",
        "  y_true = y_true_df[rating_col].values\n",
        "\n",
        "  y_pred_df = pd.merge(data_items_eval[[item_col]], df[[item_col, rating_col]], 'left').fillna(0)\n",
        "  y_pred_ndcg = y_pred_df[rating_col].values\n",
        "  y_pred_df.loc[y_pred_df[rating_col] > 0, rating_col] = 1\n",
        "  y_pred = y_pred_df[rating_col].values\n",
        "\n",
        "  if y_true.sum() >= 1:\n",
        "    score = f1_score(y_true, y_pred)\n",
        "    scores.append(score)\n",
        "\n",
        "print(\"F1 Score: \", np.mean(scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaONzUp8rsKH"
      },
      "source": [
        "# Interpretability of Bias\n",
        "\n",
        "- Find correlations between user gender and item gender (Pearsons correlation)\n",
        "- For each track get proportion of female/male user => compare train and recommendataion data\n",
        "- Check if genderness increased/decreased in recommendations (in comparision to training data) \n",
        "- Compare distribution of genderness between history and recommendations \n",
        "  - \"Delta Metric of Genderness\" (https://arxiv.org/pdf/2108.06973.pdf)\n",
        "  - Proportion tests: Fisher exact test, Chi-Square\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLkaN3VRONj6"
      },
      "outputs": [],
      "source": [
        "data_artists = pd.read_csv(\"data_artists.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "data_artists.columns = ['track_artist', 'type', 'gender_artist']\n",
        "data_user_track_interaction = pd.read_csv(\"data_user_track_interaction.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)\n",
        "data_user = pd.read_csv(\"data_user.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)\n",
        "data_user.columns = ['user_id', 'gender_user']\n",
        "\n",
        "a = []\n",
        "for i in  data_artists.track_artist.values:\n",
        "  a.append(i.lower())\n",
        "data_artists['track_artist'] = a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dewGb1xmPBXN"
      },
      "outputs": [],
      "source": [
        "df_tmp = pd.merge(data_user_track_interaction, data_user, 'inner')\n",
        "df_all = pd.merge(df_tmp, data_artists, on = 'track_artist').drop_duplicates()\n",
        "df_all = df_all.loc[(df_all['gender_artist'] != 'Unknown') & (df_all['gender_artist'] != 'other')]\n",
        "\n",
        "replace_dict1 = {'m' : 0, 'f' : 1}\n",
        "replace_dict2 = {'male' : 0, 'female' : 1}\n",
        "df_all['gender_user'] = df_all['gender_user'].replace(replace_dict1)\n",
        "df_all['gender_artist'] = df_all['gender_artist'].replace(replace_dict2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgDbgyUFYVPF"
      },
      "source": [
        "## Correlation between user and item gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4aOub4YUaga",
        "outputId": "1f0213c6-3027-44c5-e687-ff66dcc2ee80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In the history data, all female users listen to 8.3 % female itmes.\n",
            "In the history data, all male users listen to 2.67 % female itmes.\n",
            "The attributes gender_user and gender_artist show a correlation of  0.10665398232086548\n"
          ]
        }
      ],
      "source": [
        "# Proportion of female items in all female user\n",
        "prop_female = 0\n",
        "# Proportion of female items in all male user\n",
        "prop_male = 0\n",
        "for group, df in df_all.groupby('gender_user'):\n",
        "  if group == 0:\n",
        "    prop_male = df.gender_artist.sum() / len(df)\n",
        "  else:\n",
        "    prop_female = df.gender_artist.sum() / len(df)\n",
        "\n",
        "print(f'In the history data, all female users listen to {round(prop_female*100, 2)} % female itmes.')\n",
        "print(f'In the history data, all male users listen to {round(prop_male*100, 2)} % female itmes.')\n",
        "\n",
        "# Pearson correlation\n",
        "print('The attributes gender_user and gender_artist show a correlation of ', df_all.gender_user.corr(df_all.gender_artist))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_7r-GujbVZV",
        "outputId": "ca6a1922-b142-4ad9-ad24-e03caec1b036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1905224050321245e-05\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import fisher_exact\n",
        "tab = pd.crosstab(df_all.gender_user, df_all.gender_artist)\n",
        "stats, p_value = fisher_exact(tab)\n",
        "print(p_value)\n",
        "# if p-value <= 0.05 => gender_user and gender_artist are independent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEiaFN1bYdFE"
      },
      "source": [
        "## Delta metric of genderness\n",
        "\n",
        " For user u_i: (prop_female(rec) - prop_female(history)) / prop_female(history)\n",
        "\n",
        " If positive: more female tracks are recommended to the user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYomuJrr3Qj_"
      },
      "outputs": [],
      "source": [
        "df_tmp = pd.merge(results_df, data_user, 'inner')\n",
        "df_artists_tmp = pd.merge(df_tmp, data_user_track_interaction[['track_artist', 'track_id']])\n",
        "df_rec = pd.merge(df_artists_tmp, data_artists, on = 'track_artist').drop_duplicates()\n",
        "df_rec = df_rec.loc[(df_rec['gender_artist'] != 'Unknown') & (df_rec['gender_artist'] != 'other')]\n",
        "df_rec['gender_user'] = df_rec['gender_user'].replace(replace_dict1)\n",
        "df_rec['gender_artist'] = df_rec['gender_artist'].replace(replace_dict2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP_j3yQgd6Gx",
        "outputId": "75eedc37-c1a0-42de-adc8-50b810d53992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The value of delta is -1.0 and therefore more male tracks are recommended to user.\n"
          ]
        }
      ],
      "source": [
        "prop_female_rec = df_rec.gender_artist.sum()\n",
        "prop_female_history = df_all.gender_artist.sum()\n",
        "delta = (prop_female_rec - prop_female_history) / prop_female_history\n",
        "\n",
        "if delta > 0:\n",
        "  print(f'The value of delta is {delta} and therefore more female tracks are recommended to user.')\n",
        "else:\n",
        "  print(f'The value of delta is {delta} and therefore more male tracks are recommended to user.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W5yg61kZJOV"
      },
      "source": [
        "## Proportion test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IV5pBGTjYfsO"
      },
      "outputs": [],
      "source": [
        "# Fisher exact test\n",
        "\n",
        "from scipy.stats import fisher_exact\n",
        "tab = pd.crosstab(df_rec.gender_artist, df_all.gender_artist)\n",
        "stats, p_value = fisher_exact(tab)\n",
        "if p_value <= 0.05:\n",
        "  print(f'The attributes gender_artist of the history and recommendation data are significantly independent.')\n",
        "\n",
        "# if p-value <= 0.05 => gender_x and gender_y are independent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-aNSsd8cv6h",
        "outputId": "ed283829-2b4d-4865-f136-f4f439900c17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/stats/proportion.py:824: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  prop = count * 1. / nobs\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/stats/proportion.py:840: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  nobs_fact = np.sum(1. / nobs)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/stats/weightstats.py:671: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  zstat = value / std_diff\n"
          ]
        }
      ],
      "source": [
        "# z-test\n",
        "\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "significance = 0.005\n",
        "sample_size_hist = df_all.gender_artist.count()\n",
        "sample_success_hist = df_all.gender_artist.sum()\n",
        "sample_success_rec = df_rec.gender_artist.count()\n",
        "sample_size_rec = df_rec.gender_artist.sum()\n",
        "successes = np.array([sample_success_hist, sample_success_rec])\n",
        "samples = np.array([sample_size_hist, sample_size_rec])\n",
        "stat, p_value = proportions_ztest(count=successes, nobs=samples,  alternative='two-sided')\n",
        "if p_value <= 0.05:\n",
        "  print(f'The proportions of gender_artist of the history and recommendation data are significantly different.')\n",
        "# if p-value <= 0.05 => the proportions are significantly different"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict artist gender"
      ],
      "metadata": {
        "id": "NtIQzQEH2vhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "o_NzF7QQ3J6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_all_info = pd.read_csv(\"music/data_all_info.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "data_all_info = data_all_info.loc[data_all_info.artist_gender != 'other' ]"
      ],
      "metadata": {
        "id": "FducXCFxKURy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = feature_vectors\n",
        "#input = weights"
      ],
      "metadata": {
        "id": "8XV1iDFGB0mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features = pd.DataFrame()\n",
        "id_col = []\n",
        "\n",
        "for id in data_interaction_test[item_col].unique():\n",
        "  id_col.append(id)\n",
        "  df_features = df_features.append(pd.DataFrame(input[id][0].detach().numpy()))\n",
        "\n",
        "df_features[item_col] = id_col"
      ],
      "metadata": {
        "id": "Zv1QvFM3I22n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features = pd.merge(df_features, data_all_info)"
      ],
      "metadata": {
        "id": "EBOE0G_TJ28n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features.loc[df_features.artist_gender == 'female', 'artist_gender'] = 0\n",
        "df_features.loc[df_features.artist_gender == 'male', 'artist_gender'] = 1\n",
        "df_features.artist_gender = df_features.artist_gender.astype('int')"
      ],
      "metadata": {
        "id": "YOQ6VKT_IVyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_features.iloc[:,:128]\n",
        "y = df_features.artist_gender\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.4, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "2ic2xa382unN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred=clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test.values, y_pred))\n",
        "print(\"Balanced Accuracy:\", metrics.balanced_accuracy_score(y_test.values, y_pred))\n",
        "print(\"Recall: \", metrics.recall_score(y_test.values, y_pred))\n",
        "print(\"Precision: \", metrics.precision_score(y_test.values, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h50TBcLs3G7l",
        "outputId": "6a0f5c73-0cde-43ab-f254-0c7429c0e2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7887323943661971\n",
            "Balanced Accuracy: 0.7465686274509804\n",
            "Recall:  0.8431372549019608\n",
            "Precision:  0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "feature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\n",
        "feature_imp.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQSgoDfe4Cc4",
        "outputId": "d28f5393-a801-4ce2-bd4a-a85e55df7656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104    0.226804\n",
              "98     0.140306\n",
              "17     0.131687\n",
              "81     0.114796\n",
              "127    0.111745\n",
              "62     0.091315\n",
              "5      0.083488\n",
              "111    0.051955\n",
              "3      0.047903\n",
              "69     0.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d-l5O-0D2dm"
      },
      "source": [
        "---------------------------\n",
        "\n",
        "# Next steps\n",
        "\n",
        "[x] Train test split \n",
        "\n",
        "[x] Implement CV\n",
        "\n",
        "[x] Balance data set (use as many listened as unlistened tracks - randomly chosing them)\n",
        "\n",
        "[x] Use Popularity model as baseline\n",
        "\n",
        "[x] Check index behaviour!!! (pos2item,...)\n",
        "\n",
        "[x] Test/train split (https://colab.research.google.com/github/d2l-ai/d2l-en-colab/blob/master/chapter_recommender-systems/movielens.ipynb)\n",
        "\n",
        "[x] Verify BERT Tokenizer\n",
        "\n",
        "[x] Verify data reading with new movie data\n",
        "\n",
        "[x] Try out gender interpretability\n",
        "\n",
        "[ ] Add tags data (instead of lyrics)\n",
        "\n",
        "[x] Get more data\n",
        "\n",
        "[x] Clean lyrics data (remove non-english ones and repeated parts)\n",
        "\n",
        "[x] Use embedding of model to predict gender of artist\n",
        "\n",
        "[x] Try to find song writer gender (not priority) => tried this out but could not find a general solution\n",
        "\n",
        "[ ] Implement ndcg (https://github.com/Jenniferz28/Collaborative-Filtering-Recommendation/blob/69a2400736a628de34620318abe861cc9a19e621/ndcg.py#L77)\n",
        "\n",
        "[ ] Clean up code and move to repository\n",
        "\n",
        "[ ] Implement evaluation with using all items in dataset\n",
        "\n",
        "[ ] BERT make sure this is correct!\n",
        "\n",
        "[ ] Try out correlation interpretability things (e.g. \"Exploring Artist Gender Bias in Music Recommendation\"\n",
        "\n",
        "[ ] Remove 'important' feature vector from recommendataion model and compare recommendation performance + prediction perforamcne\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "UaONzUp8rsKH",
        "hgDbgyUFYVPF",
        "UEiaFN1bYdFE",
        "_W5yg61kZJOV"
      ],
      "machine_shape": "hm",
      "name": "MasterThesis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMTl7rDRtwItbbodeRhkgzh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}