{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Katrin-Leberfinger/Hybrid-gender-debiased-music-recommendation/blob/main/models_using_lfm2b_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkBFbi9YA_ys"
      },
      "source": [
        "# BERT for text embedding\n",
        "\n",
        "Code Source:\n",
        "https://gist.github.com/shubhamagarwal92/37ccb747f7130a35a8e76aa66d60e014\n",
        "\n",
        "Interesting articles\n",
        "https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#31-running-bert-on-our-text\n",
        "https://www.kaggle.com/hassanamin/bert-pytorch-cola-classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWHMmzSHaV4j",
        "outputId": "7fe84bd7-609e-4d73-f0a7-8ac0bc5fab99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 72.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 66.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 93.4 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.5 transformers-4.16.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L9D-5zOmltBw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from transformers import BertConfig, BertPreTrainedModel, BertModel, BertForSequenceClassification\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertModel, AdamW\n",
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "from sklearn.metrics import f1_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXEH2KDKXjCM"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4wBsH6CFBrhZ"
      },
      "outputs": [],
      "source": [
        "# data: track_artist -\ttrack_name -\ttrack_tag - track_id\n",
        "\n",
        "def read_items_data_bert(data, id_col, text_col, max_length=512):\n",
        "  tokenizer = BertTokenizer.from_pretrained('prajjwal1/bert-tiny') \n",
        "  #tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') \n",
        "  items = torch.Tensor([])\n",
        "  attentions = torch.Tensor([])\n",
        "  item2pos = dict()\n",
        "  pos2item = dict()\n",
        "  token2id = dict()\n",
        "  num_items = 0\n",
        "  num_tokens = 0\n",
        "  max_item_len = 0\n",
        "\n",
        "  for index, row in data.iterrows():\n",
        "    # for each item:\n",
        "    item_id = row[id_col]\n",
        "    item_words = []\n",
        "    item2pos[item_id] = num_items\n",
        "    pos2item[num_items] = item_id\n",
        "\n",
        "\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        row[text_col], \n",
        "        None,\n",
        "        add_special_tokens=True,\n",
        "        max_length = max_length,\n",
        "        pad_to_max_length=True\n",
        "        \n",
        "    )\n",
        "\n",
        "    tokens = inputs[\"input_ids\"]\n",
        "    attention = inputs['attention_mask']\n",
        "    tokens=torch.tensor(tokens, dtype=torch.long).unsqueeze(0)\n",
        "    attention=torch.tensor(attention, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "    items = torch.concat((items, tokens))\n",
        "    attentions = torch.concat((attentions, attention))\n",
        "    num_items = num_items + 1\n",
        "\n",
        "  return items, attentions, item2pos, pos2item, token2id, max_item_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MXu90sp8XmdZ"
      },
      "outputs": [],
      "source": [
        "# data: user_id - item_id - rating\n",
        "# playcount: normalize/ binary (>1:1 or <=1:0)\n",
        "\n",
        "def read_ratings_data(data, item2pos, id_col, rating_col, user_col):\n",
        "    ratings = torch.Tensor(len(data), 3)\n",
        "    user2id = dict()\n",
        "    id2user = dict()\n",
        "    num_users = 0\n",
        "    i = 0\n",
        "    for _, row in data.iterrows():\n",
        "        raw_user = row[user_col] \n",
        "\n",
        "        try:\n",
        "          user2id[raw_user]\n",
        "        except:\n",
        "          user2id[raw_user] = num_users\n",
        "          id2user[num_users] = raw_user\n",
        "          num_users = num_users + 1\n",
        "\n",
        "        user = user2id[raw_user]\n",
        "        item = int(item2pos[row[id_col]]) #track_id\n",
        "        rating = int(row[rating_col]) # count\n",
        "\n",
        "        ratings[i][0] = user\n",
        "        ratings[i][1] = item\n",
        "        ratings[i][2] = rating / data[rating_col].max()\n",
        "        i = i+1\n",
        "\n",
        "\n",
        "    return ratings, user2id, id2user\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzTFm7XWXmXv",
        "outputId": "85994083-ea2f-4cb7-c51b-b5559ceab2d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWWKtwJxXmQC",
        "outputId": "edbc1f69-7b5e-45eb-fffa-de1c1335f242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Master Thesis/data\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Master\\ Thesis/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf103qDF0cNv"
      },
      "source": [
        "## Read Data: Lyrics "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "lTSGXhgqhfXI"
      },
      "outputs": [],
      "source": [
        "data_tracks_lyrics = pd.read_csv(\"music/data_tracks_lyrics.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "data_tracks_tags_lyrics = pd.read_csv(\"music/data_tracks_tags_lyrics.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "#data_tracks_tags_lyrics=data_tracks_tags_lyrics.iloc[:-1,:]\n",
        "data_interaction = pd.read_csv(\"music/data_user_track_interaction.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)\n",
        "data_user = pd.read_csv(\"music/data_user.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "selected_user = random.sample(list(data_interaction.user_id.unique()), 800)\n",
        "data_interaction = data_interaction.loc[data_interaction.user_id.isin(selected_user)]"
      ],
      "metadata": {
        "id": "D7yq3WIEPMNF"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = 0\n",
        "i = 0\n",
        "for d in data_tracks_lyrics['lyrics_cleaned']:\n",
        "  l = l+ len(d.split())\n",
        "  i = i+1\n",
        "l/i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPtSd2-TXWHl",
        "outputId": "d1f752cb-bbe5-438c-e01b-9c0a648bf889"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255.5098647125141"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "6OhaSF-4unXz"
      },
      "outputs": [],
      "source": [
        "data_interaction.loc[data_interaction['count']<2., 'count'] = 0.\n",
        "data_interaction.loc[data_interaction['count']>=2., 'count'] = 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "i9FIxII88I0k"
      },
      "outputs": [],
      "source": [
        "rating_col = 'count'\n",
        "item_col = 'track_id'\n",
        "user_col = 'user_id'\n",
        "text_col = 'tags'\n",
        "data_items_eval = data_tracks_tags_lyrics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CV and balance data set"
      ],
      "metadata": {
        "id": "ylBY96MuqFyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_interaction['fold'] = np.random.randint(1, 6, data_interaction.shape[0])\n",
        "\n",
        "import random\n",
        "idx = []\n",
        "for _,df in data_interaction.groupby('fold'):\n",
        "  len_pos = len(df[df[rating_col]==1])\n",
        "  len_neg = len(df[df[rating_col]==0])\n",
        "  if len_pos < len_neg:\n",
        "    df = df[df[rating_col]==0].sample(len_pos).append(df[df[rating_col]==1])\n",
        "  elif len_pos > len_neg:\n",
        "    df = df[df[rating_col]==1].sample(len_pos).append(df[df[rating_col]==0])\n",
        "  idx.extend(df.index.values.tolist())\n",
        "\n",
        "test_fold = 1\n",
        "\n",
        "data_interaction_train = data_interaction.loc[data_interaction.fold != test_fold, [user_col, item_col, rating_col]]\n",
        "data_interaction_test = data_interaction.loc[data_interaction.fold == test_fold, [user_col, item_col, rating_col]]"
      ],
      "metadata": {
        "id": "MR65uPJ6qE9R"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1VnHcVWBFIP"
      },
      "source": [
        "# Ask Me Anything Rating\n",
        "\n",
        "Code source: https://github.com/nlp-deepcbrs/amar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbf_Xg4sE_gu"
      },
      "source": [
        "## **BERT Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrDzG95DcA_8",
        "outputId": "5aeab280-ded8-49c8-b2c9-70645d45a084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "items, attentions, item2pos, pos2item, token2id, max_item_len = read_items_data_bert(data_items_eval, item_col, text_col, 128)\n",
        "ratings_train, user2id_train, id2user_train = read_ratings_data(data_interaction_train, item2pos,  item_col, rating_col, user_col)\n",
        "\n",
        "ratings_test, user2id_test, id2user_test = read_ratings_data(data_interaction_test, item2pos,  item_col, rating_col, user_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "GHWjCxuHb6cX"
      },
      "outputs": [],
      "source": [
        "class AMARBert(nn.Module):\n",
        "    def __init__(self, hidden_dense_layer_size, item_embeddings_size, num_users):\n",
        "        super(AMARBert, self).__init__()\n",
        "        #self.model1_layer2 = BertModel.from_pretrained('prajjwal1/bert-tiny')#('bert-base-uncased')\n",
        "        self.model1_layer2 = BertModel.from_pretrained('prajjwal1/bert-tiny')\n",
        "        self.model1_layer3 = nn.Dropout(p=0.2)\n",
        "\n",
        "        self.model2_layer1 = nn.Embedding(num_users, user_embeddings_size)\n",
        "        \n",
        "        self.linear = nn.Linear(hidden_dense_layer_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #_, y1 = self.model1_layer2(x[0], attention_mask = x[2],  return_dict=False)\n",
        "        output, y1 = self.model1_layer2(x[0],  return_dict=False)\n",
        "        #y1 = output[:, 0, :]\n",
        "        # pooled_output (=y1) is the output of the CLS token\n",
        "        # \"Since BERT is transformer based contextual model, the idea is [CLS] token would have captured the entire context and would be sufficient for simple downstream tasks such as classification.\"\n",
        "        # https://stackoverflow.com/questions/63673511/how-to-use-the-outputs-of-bert-model?rq=1\n",
        "        # https://towardsdatascience.com/bert-to-the-rescue-17671379687f\n",
        "       # y1 = self.model1_layer3(y1)\n",
        "        \n",
        "        y2 = self.model2_layer1(x[1])\n",
        "\n",
        "        y = torch.cat([y1, y2], 1)\n",
        "        y = self.linear(y)\n",
        "        return self.sigmoid(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJdsCzCuqzHQ",
        "outputId": "883ec9c9-d124-4de1-d7f3-0e24f53f7fe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Params: items_data, ratings_data, genres_data\n",
        "device = 'cuda'\n",
        "\n",
        "import numpy as np\n",
        "num_examples=ratings_train.size(0)\n",
        "item_embeddings_size = 128\n",
        "user_embeddings_size = 100\n",
        "genre_embeddings_size = 128\n",
        "hidden_dense_layer_size = item_embeddings_size + user_embeddings_size\n",
        "num_users = len(data_interaction[user_col].drop_duplicates())\n",
        "\n",
        "model = AMARBert( hidden_dense_layer_size, item_embeddings_size, num_users)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Vnqy-3XBqQ6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36974a1a-f829-46a7-9b44-25e264352ff2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average cost per epoch:  tensor(0.6958, grad_fn=<DivBackward0>)\n",
            "Average cost per epoch:  tensor(0.6910, grad_fn=<DivBackward0>)\n",
            "Average cost per epoch:  tensor(0.6852, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "criterion = nn.BCEWithLogitsLoss() \n",
        "# # https://huggingface.co/transformers/v1.0.0/migration.html\n",
        "lr = 1e-3\n",
        "num_total_steps = 1000\n",
        "num_warmup_steps = 100\n",
        "warmup_proportion = float(num_warmup_steps) / float(num_total_steps)  \n",
        "optimizer = AdamW(model.parameters(), lr=lr, correct_bias=False)  \n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "   optimizer,\n",
        "   num_warmup_steps=num_warmup_steps,\n",
        "   num_training_steps=num_total_steps\n",
        ")\n",
        "\n",
        "\n",
        "num_epochs=3\n",
        "batch_size=256 \n",
        "#batch_size=32\n",
        "num_examples=ratings_train.shape[0]\n",
        "\n",
        "cost_per_epoch = []\n",
        "\n",
        "for e in range(num_epochs):\n",
        "    # shuffle and split training examples in batches\n",
        "    indices = torch.randperm(num_examples).split(batch_size)\n",
        "\n",
        "    #remove last element so that all the batches have equal size\n",
        "    indices = indices[:len(indices)-1] \n",
        "\n",
        "    average_cost = 0\n",
        "\n",
        "    for t, v in enumerate(indices):\n",
        "        #items positions\n",
        "        curr_items_ids_batch = ratings_train[v, 1]\n",
        "\n",
        "        # items descriptions\n",
        "        curr_items_batch = items[curr_items_ids_batch.numpy(),:].to(device)\n",
        "        curr_attentions_batch = attentions[curr_items_ids_batch.numpy(),:].to(device)\n",
        "        \n",
        "        # users ids\n",
        "        curr_users_batch = ratings_train[v, 0].to(device)\n",
        "\n",
        "        # model inputs\n",
        "        inputs = [ curr_items_batch.type(torch.LongTensor), curr_users_batch.type(torch.LongTensor), curr_attentions_batch.type(torch.LongTensor)]\n",
        "\n",
        "        # model targets\n",
        "        targets = ratings_train[v, 2]\n",
        "\n",
        "        # callback that does a single batch optimization step\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # backward propagation\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        \n",
        "        outputs = outputs.reshape(-1,)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        # evaluate current loss function value\n",
        "        average_cost = average_cost + loss\n",
        "        \n",
        "\n",
        "    # evaluate average cost per epoch\n",
        "    average_cost = average_cost / len(indices)\n",
        "    cost_per_epoch.append(average_cost)\n",
        "    print(\"Average cost per epoch: \", average_cost)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGVytV4uSHmc",
        "outputId": "72951021-88af-4c80-9d35-550302666833"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9033, grad_fn=<MaxBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTzPCnbSpZX7",
        "outputId": "3cb6dd67-ea36-4c13-a35a-a9399cfa09b3"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0040, grad_fn=<MinBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH1Njid6OwL8"
      },
      "source": [
        "## **BERT**: Get predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feature_vector(model, inputs, batch_size):\n",
        "\n",
        "  layer = model._modules.get('model1_layer3')\n",
        "\n",
        "  embedding = torch.zeros((batch_size, 128))\n",
        "  def copy_data(m, i, o):\n",
        "          embedding.copy_(o.data)\n",
        "  h = layer.register_forward_hook(copy_data)\n",
        "  model(inputs)\n",
        "  h.remove()\n",
        "  return embedding"
      ],
      "metadata": {
        "id": "KWP35qY4K6vX"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ3Akda8KGkF"
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "\n",
        "indices = ratings_test[:,0].unique()\n",
        "predictions = {}\n",
        "feature_vectors = {}\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for curr_users_batch in indices:\n",
        "\n",
        "  curr_users_batch = curr_users_batch.to(device).reshape(-1)\n",
        " # curr_users_batch = curr_users_batch.repeat(batch_size)\n",
        "  indices_items = ratings_test[:,1].unique()#.split(batch_size)[:-1]\n",
        "  for curr_items_ids_batch in indices_items:\n",
        "    \n",
        "    curr_items_ids_batch = int(curr_items_ids_batch.item())\n",
        "\n",
        "    curr_items_batch = items[curr_items_ids_batch,:].to(device).reshape(1, -1)\n",
        "    \n",
        "    \n",
        "    curr_attentions_batch = attentions[curr_items_ids_batch,:].to(device).reshape(1, -1)\n",
        "\n",
        "    inputs = [ curr_items_batch.type(torch.LongTensor), curr_users_batch.type(torch.LongTensor), curr_attentions_batch.type(torch.LongTensor)]\n",
        "    \n",
        "    targets = model(inputs)\n",
        "    item_list = []\n",
        "    \n",
        "    \n",
        "    # save prediction for each user\n",
        "    real_user_id = id2user_test[curr_users_batch[0].item()]\n",
        "\n",
        "    for i in range(targets.shape[0]):\n",
        "    \n",
        "      try:\n",
        "        predictions[real_user_id] \n",
        "      except:\n",
        "        predictions[real_user_id] = []\n",
        "\n",
        "      predictions[real_user_id].append([pos2item[curr_items_ids_batch], \n",
        "                                        targets[i].item()])\n",
        "    \n",
        "    # save embedding layer for each item\n",
        "    feature_vector = get_feature_vector(model, inputs, batch_size)\n",
        "    try:\n",
        "      feature_vectors[pos2item[curr_items_ids_batch]]\n",
        "    except:\n",
        "      feature_vectors[pos2item[curr_items_ids_batch]] = []\n",
        "    feature_vectors[pos2item[curr_items_ids_batch]].append(feature_vector)\n",
        "        \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epmQfDr0Vvzc"
      },
      "outputs": [],
      "source": [
        "topn=10\n",
        "results = []\n",
        "results_df = pd.DataFrame(columns = [user_col, item_col, rating_col])\n",
        "\n",
        "for user in predictions:\n",
        "    item_list = []\n",
        "    user_prediction = predictions[user]\n",
        "\n",
        "    user_prediction = sorted(user_prediction,key=lambda x: (x[1]), reverse=True)\n",
        "    n = 1\n",
        "    for item, rating in user_prediction:\n",
        "        if item  not in item_list:\n",
        "          item_list.append(item)\n",
        "          results_df = pd.concat((results_df, pd.DataFrame(data={user_col:[user],item_col:[item],rating_col:[rating]})))\n",
        "          results.append([user, item, rating])\n",
        "          if n >= topn:\n",
        "              break\n",
        "          n = n + 1\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxzLZWaLAhUZ"
      },
      "source": [
        "# Evaluate predictions\n",
        "\n",
        "Scores: F1@10, ndcg, MAP@k"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ndcg_at(predictions, labels, k=10, assume_unique=True):\n",
        "    \"\"\"Compute the normalized discounted cumulative gain at K.\n",
        "    Compute the average NDCG value of all the queries, truncated at ranking\n",
        "    position k. The discounted cumulative gain at position k is computed as:\n",
        "        sum,,i=1,,^k^ (2^{relevance of ''i''th item}^ - 1) / log(i + 1)\n",
        "    and the NDCG is obtained by dividing the DCG value on the ground truth set.\n",
        "    In the current implementation, the relevance value is binary.\n",
        "    If a query has an empty ground truth set, zero will be used as\n",
        "    NDCG together with a warning.\n",
        "    Source: https://gist.github.com/tgsmith61591/d8aa96ac7c74c24b33e4b0cb967ca519\n",
        "    Parameters\n",
        "    ----------\n",
        "    predictions : array-like, shape=(n_predictions,)\n",
        "        The prediction array. The items that were predicted, in descending\n",
        "        order of relevance.\n",
        "    labels : array-like, shape=(n_ratings,)\n",
        "        The labels (positively-rated items).\n",
        "    k : int, optional (default=10)\n",
        "        The rank at which to measure the NDCG.\n",
        "    assume_unique : bool, optional (default=True)\n",
        "        Whether to assume the items in the labels and predictions are each\n",
        "        unique. That is, the same item is not predicted multiple times or\n",
        "        rated multiple times.\n",
        "    Examples\n",
        "    --------\n",
        "    >>> # predictions for 3 users\n",
        "    >>> preds = [[1, 6, 2, 7, 8, 3, 9, 10, 4, 5],\n",
        "    ...          [4, 1, 5, 6, 2, 7, 3, 8, 9, 10],\n",
        "    ...          [1, 2, 3, 4, 5]]\n",
        "    >>> # labels for the 3 users\n",
        "    >>> labels = [[1, 2, 3, 4, 5], [1, 2, 3], []]\n",
        "    >>> ndcg_at(preds, labels, 3)\n",
        "    0.3333333432674408\n",
        "    >>> ndcg_at(preds, labels, 10)\n",
        "    0.48791273434956867\n",
        "    References\n",
        "    ----------\n",
        "    .. [1] K. Jarvelin and J. Kekalainen, \"IR evaluation methods for\n",
        "           retrieving highly relevant documents.\"\n",
        "    \"\"\"\n",
        "\n",
        "    def _inner_ndcg(pred, lab):\n",
        "        # if we do NOT assume uniqueness, the set is a bit different here\n",
        "        if not assume_unique:\n",
        "            lab = np.unique(lab)\n",
        "\n",
        "        n_lab = lab.shape[0]\n",
        "        n_pred = pred.shape[0]\n",
        "        n = min(max(n_pred, n_lab), k)  # min(min(p, l), k)?\n",
        "\n",
        "        # similar to mean_avg_prcsn, we need an arange, but this time +2\n",
        "        # since python is zero-indexed, and the denom typically needs +1.\n",
        "        # Also need the log base2...\n",
        "        arange = np.arange(n, dtype=np.float32)  # length n\n",
        "\n",
        "        # since we are only interested in the arange up to n_pred, truncate\n",
        "        # if necessary\n",
        "        arange = arange[:n_pred]\n",
        "        denom = np.log2(arange + 2.)  # length n\n",
        "        gains = 1. / denom  # length n\n",
        "\n",
        "        # compute the gains where the prediction is present in the labels\n",
        "        dcg_mask = np.in1d(pred[:n], lab, assume_unique=assume_unique)\n",
        "        dcg = gains[dcg_mask].sum()\n",
        "\n",
        "        # the max DCG is sum of gains where the index < the label set size\n",
        "        max_dcg = gains[arange < n_lab].sum()\n",
        "        return dcg / max_dcg\n",
        "\n",
        "\n",
        "    return _inner_ndcg(predictions, labels)"
      ],
      "metadata": {
        "id": "81X0D6wvfHKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def ndcg(rel_true, rel_pred, p=None):\n",
        "    rel_true = np.sort(rel_true)[::-1]\n",
        "    p = min(len(rel_true), min(len(rel_pred), p))\n",
        "    discount = 1 / (np.log2(np.arange(p) + 2))\n",
        "\n",
        "    idcg = np.sum(rel_true[:p] * discount)\n",
        "    dcg = np.sum(rel_pred[:p] * discount)\n",
        "    \n",
        "    return dcg / idcg\n",
        "\n",
        "\n",
        "song_index = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}\n",
        "user_lists = [\"USER1\", \"USER2\", \"USER3\"]\n",
        "\n",
        "relevance_true = {\n",
        "    \"USER1\": [3, 3, 2, 2, 1, 1, 0, 0, 0],\n",
        "    \"USER2\": [3, 2, 1, 1, 2, 0, 1, 1, 1],\n",
        "    \"USER3\": [0, 1, 0, 1, 2, 3, 3, 1, 0]\n",
        "}\n",
        "\n",
        "user = user_lists[0]\n",
        "r_true = relevance_true[user]\n",
        "\n",
        "s1_pred = [r_true[song_index[song]] for song in s1_prediction[user]]\n",
        "\n",
        "print(f'S1 nDCG@5 (linear): {ndcg(r_true, s1_pred, 5)}')\n",
        "print(f'S2 nDCG@5 (linear): {ndcg(true_relevance.tolist()[0], scores.tolist()[0], 6)}')\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iv8LOOpdhY0y",
        "outputId": "050f1a8e-a1c2-49dc-a5f7-d8b1a5014ab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S1 nDCG@5 (linear): 0.8232936061974518\n",
            "S2 nDCG@5 (linear): 0.785002371969948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DTstEsi72xS"
      },
      "outputs": [],
      "source": [
        "scores = []\n",
        "for user, df in results_df.groupby(user_col):\n",
        "  df = df.drop_duplicates(subset=item_col)\n",
        "  y_true_sorted = data_interaction_test.loc[data_interaction_test[user_col] == user].sort_values(rating_col, ascending=False)\n",
        "  y_true_df = pd.merge(data_items_eval[[item_col]], y_true_sorted[[item_col, rating_col]], 'left').fillna(0)\n",
        "  y_true_ndcg = y_true_df[rating_col].values\n",
        "  y_true_df.loc[y_true_df[rating_col] > 0, rating_col] = 1\n",
        "  y_true = y_true_df[rating_col].values\n",
        "\n",
        "  y_pred_df = pd.merge(data_items_eval[[item_col]], df[[item_col, rating_col]], 'left').fillna(0)\n",
        "  y_pred_ndcg = y_pred_df[rating_col].values\n",
        "  y_pred_df.loc[y_pred_df[rating_col] > 0, rating_col] = 1\n",
        "  y_pred = y_pred_df[rating_col].values\n",
        "\n",
        "  if y_true.sum() >= 1:\n",
        "    score = f1_score(y_true, y_pred)\n",
        "    scores.append(score)\n",
        "\n",
        "print(\"F1 Score: \", np.mean(scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaONzUp8rsKH"
      },
      "source": [
        "# Interpretability of Bias\n",
        "\n",
        "- Find correlations between user gender and item gender (Pearsons correlation)\n",
        "- For each track get proportion of female/male user => compare train and recommendataion data\n",
        "- Check if genderness increased/decreased in recommendations (in comparision to training data) \n",
        "- Compare distribution of genderness between history and recommendations \n",
        "  - \"Delta Metric of Genderness\" (https://arxiv.org/pdf/2108.06973.pdf)\n",
        "  - Proportion tests: Fisher exact test, Chi-Square\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLkaN3VRONj6"
      },
      "outputs": [],
      "source": [
        "data_artists = pd.read_csv(\"data_artists.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "data_artists.columns = ['track_artist', 'type', 'gender_artist']\n",
        "data_user_track_interaction = pd.read_csv(\"data_user_track_interaction.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)\n",
        "data_user = pd.read_csv(\"data_user.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1)\n",
        "data_user.columns = ['user_id', 'gender_user']\n",
        "\n",
        "a = []\n",
        "for i in  data_artists.track_artist.values:\n",
        "  a.append(i.lower())\n",
        "data_artists['track_artist'] = a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dewGb1xmPBXN"
      },
      "outputs": [],
      "source": [
        "df_tmp = pd.merge(data_user_track_interaction, data_user, 'inner')\n",
        "df_all = pd.merge(df_tmp, data_artists, on = 'track_artist').drop_duplicates()\n",
        "df_all = df_all.loc[(df_all['gender_artist'] != 'Unknown') & (df_all['gender_artist'] != 'other')]\n",
        "\n",
        "replace_dict1 = {'m' : 0, 'f' : 1}\n",
        "replace_dict2 = {'male' : 0, 'female' : 1}\n",
        "df_all['gender_user'] = df_all['gender_user'].replace(replace_dict1)\n",
        "df_all['gender_artist'] = df_all['gender_artist'].replace(replace_dict2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgDbgyUFYVPF"
      },
      "source": [
        "## Correlation between user and item gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4aOub4YUaga",
        "outputId": "1f0213c6-3027-44c5-e687-ff66dcc2ee80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In the history data, all female users listen to 8.3 % female itmes.\n",
            "In the history data, all male users listen to 2.67 % female itmes.\n",
            "The attributes gender_user and gender_artist show a correlation of  0.10665398232086548\n"
          ]
        }
      ],
      "source": [
        "# Proportion of female items in all female user\n",
        "prop_female = 0\n",
        "# Proportion of female items in all male user\n",
        "prop_male = 0\n",
        "for group, df in df_all.groupby('gender_user'):\n",
        "  if group == 0:\n",
        "    prop_male = df.gender_artist.sum() / len(df)\n",
        "  else:\n",
        "    prop_female = df.gender_artist.sum() / len(df)\n",
        "\n",
        "print(f'In the history data, all female users listen to {round(prop_female*100, 2)} % female itmes.')\n",
        "print(f'In the history data, all male users listen to {round(prop_male*100, 2)} % female itmes.')\n",
        "\n",
        "# Pearson correlation\n",
        "print('The attributes gender_user and gender_artist show a correlation of ', df_all.gender_user.corr(df_all.gender_artist))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_7r-GujbVZV",
        "outputId": "ca6a1922-b142-4ad9-ad24-e03caec1b036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1905224050321245e-05\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import fisher_exact\n",
        "tab = pd.crosstab(df_all.gender_user, df_all.gender_artist)\n",
        "stats, p_value = fisher_exact(tab)\n",
        "print(p_value)\n",
        "# if p-value <= 0.05 => gender_user and gender_artist are independent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEiaFN1bYdFE"
      },
      "source": [
        "## Delta metric of genderness\n",
        "\n",
        " For user u_i: (prop_female(rec) - prop_female(history)) / prop_female(history)\n",
        "\n",
        " If positive: more female tracks are recommended to the user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYomuJrr3Qj_"
      },
      "outputs": [],
      "source": [
        "df_tmp = pd.merge(results_df, data_user, 'inner')\n",
        "df_artists_tmp = pd.merge(df_tmp, data_user_track_interaction[['track_artist', 'track_id']])\n",
        "df_rec = pd.merge(df_artists_tmp, data_artists, on = 'track_artist').drop_duplicates()\n",
        "df_rec = df_rec.loc[(df_rec['gender_artist'] != 'Unknown') & (df_rec['gender_artist'] != 'other')]\n",
        "df_rec['gender_user'] = df_rec['gender_user'].replace(replace_dict1)\n",
        "df_rec['gender_artist'] = df_rec['gender_artist'].replace(replace_dict2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP_j3yQgd6Gx",
        "outputId": "75eedc37-c1a0-42de-adc8-50b810d53992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The value of delta is -1.0 and therefore more male tracks are recommended to user.\n"
          ]
        }
      ],
      "source": [
        "prop_female_rec = df_rec.gender_artist.sum()\n",
        "prop_female_history = df_all.gender_artist.sum()\n",
        "delta = (prop_female_rec - prop_female_history) / prop_female_history\n",
        "\n",
        "if delta > 0:\n",
        "  print(f'The value of delta is {delta} and therefore more female tracks are recommended to user.')\n",
        "else:\n",
        "  print(f'The value of delta is {delta} and therefore more male tracks are recommended to user.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W5yg61kZJOV"
      },
      "source": [
        "## Proportion test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IV5pBGTjYfsO"
      },
      "outputs": [],
      "source": [
        "# Fisher exact test\n",
        "\n",
        "from scipy.stats import fisher_exact\n",
        "tab = pd.crosstab(df_rec.gender_artist, df_all.gender_artist)\n",
        "stats, p_value = fisher_exact(tab)\n",
        "if p_value <= 0.05:\n",
        "  print(f'The attributes gender_artist of the history and recommendation data are significantly independent.')\n",
        "\n",
        "# if p-value <= 0.05 => gender_x and gender_y are independent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-aNSsd8cv6h",
        "outputId": "ed283829-2b4d-4865-f136-f4f439900c17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/stats/proportion.py:824: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  prop = count * 1. / nobs\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/stats/proportion.py:840: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  nobs_fact = np.sum(1. / nobs)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/stats/weightstats.py:671: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  zstat = value / std_diff\n"
          ]
        }
      ],
      "source": [
        "# z-test\n",
        "\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "significance = 0.005\n",
        "sample_size_hist = df_all.gender_artist.count()\n",
        "sample_success_hist = df_all.gender_artist.sum()\n",
        "sample_success_rec = df_rec.gender_artist.count()\n",
        "sample_size_rec = df_rec.gender_artist.sum()\n",
        "successes = np.array([sample_success_hist, sample_success_rec])\n",
        "samples = np.array([sample_size_hist, sample_size_rec])\n",
        "stat, p_value = proportions_ztest(count=successes, nobs=samples,  alternative='two-sided')\n",
        "if p_value <= 0.05:\n",
        "  print(f'The proportions of gender_artist of the history and recommendation data are significantly different.')\n",
        "# if p-value <= 0.05 => the proportions are significantly different"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict artist gender"
      ],
      "metadata": {
        "id": "NtIQzQEH2vhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "o_NzF7QQ3J6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_all_info = pd.read_csv(\"music/data_all_info.txt\", sep=\"\\t\").drop(['Unnamed: 0'],axis=1).dropna()\n",
        "data_all_info = data_all_info.loc[data_all_info.artist_gender != 'other' ]"
      ],
      "metadata": {
        "id": "FducXCFxKURy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = feature_vectors"
      ],
      "metadata": {
        "id": "8XV1iDFGB0mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features = pd.DataFrame()\n",
        "id_col = []\n",
        "\n",
        "for id in data_interaction_test[item_col].unique():\n",
        "  id_col.append(id)\n",
        "  df_features = df_features.append(pd.DataFrame(input[id][0].detach().numpy()))\n",
        "\n",
        "df_features[item_col] = id_col"
      ],
      "metadata": {
        "id": "Zv1QvFM3I22n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features = pd.merge(df_features, data_all_info)"
      ],
      "metadata": {
        "id": "EBOE0G_TJ28n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features.loc[df_features.artist_gender == 'female', 'artist_gender'] = 0\n",
        "df_features.loc[df_features.artist_gender == 'male', 'artist_gender'] = 1\n",
        "df_features.artist_gender = df_features.artist_gender.astype('int')"
      ],
      "metadata": {
        "id": "YOQ6VKT_IVyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_features.iloc[:,:128]\n",
        "y = df_features.artist_gender\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.4, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "2ic2xa382unN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred=clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test.values, y_pred))\n",
        "print(\"Balanced Accuracy:\", metrics.balanced_accuracy_score(y_test.values, y_pred))\n",
        "print(\"Recall: \", metrics.recall_score(y_test.values, y_pred))\n",
        "print(\"Precision: \", metrics.precision_score(y_test.values, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h50TBcLs3G7l",
        "outputId": "6a0f5c73-0cde-43ab-f254-0c7429c0e2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7887323943661971\n",
            "Balanced Accuracy: 0.7465686274509804\n",
            "Recall:  0.8431372549019608\n",
            "Precision:  0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "feature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\n",
        "feature_imp.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQSgoDfe4Cc4",
        "outputId": "d28f5393-a801-4ce2-bd4a-a85e55df7656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104    0.226804\n",
              "98     0.140306\n",
              "17     0.131687\n",
              "81     0.114796\n",
              "127    0.111745\n",
              "62     0.091315\n",
              "5      0.083488\n",
              "111    0.051955\n",
              "3      0.047903\n",
              "69     0.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d-l5O-0D2dm"
      },
      "source": [
        "---------------------------\n",
        "\n",
        "# Next steps\n",
        "\n",
        "[x] Train test split \n",
        "\n",
        "[x] Implement CV\n",
        "\n",
        "[x] Balance data set (use as many listened as unlistened tracks - randomly chosing them)\n",
        "\n",
        "[x] Use Popularity model as baseline\n",
        "\n",
        "[x] Check index behaviour!!! (pos2item,...)\n",
        "\n",
        "[x] Test/train split (https://colab.research.google.com/github/d2l-ai/d2l-en-colab/blob/master/chapter_recommender-systems/movielens.ipynb)\n",
        "\n",
        "[x] Verify BERT Tokenizer\n",
        "\n",
        "[x] Verify data reading with new movie data\n",
        "\n",
        "[x] Try out gender interpretability\n",
        "\n",
        "[x] Add tags data (instead of lyrics)\n",
        "\n",
        "[x] Get more data\n",
        "\n",
        "[x] Clean lyrics data (remove non-english ones and repeated parts)\n",
        "\n",
        "[x] Use embedding of model to predict gender of artist\n",
        "\n",
        "[x] Try to find song writer gender (not priority) => tried this out but could not find a general solution\n",
        "\n",
        "[ ] Implement ndcg (https://github.com/Jenniferz28/Collaborative-Filtering-Recommendation/blob/69a2400736a628de34620318abe861cc9a19e621/ndcg.py#L77)\n",
        "\n",
        "[x] Clean up code and move to repository\n",
        "\n",
        "[x] Implement evaluation with using all items in dataset\n",
        "\n",
        "[ ] BERT make sure this is correct!\n",
        "\n",
        "[ ] Try out correlation interpretability things (e.g. \"Exploring Artist Gender Bias in Music Recommendation\"\n",
        "\n",
        "[ ] Remove 'important' feature vector from recommendataion model and compare recommendation performance + prediction perforamcne\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "UaONzUp8rsKH",
        "hgDbgyUFYVPF",
        "UEiaFN1bYdFE",
        "_W5yg61kZJOV"
      ],
      "machine_shape": "hm",
      "name": "MasterThesis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMC2gYuGMFoMs/hTRmiLx+9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}